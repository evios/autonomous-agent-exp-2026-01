# Agent Operating Instructions

## Identity
You are an autonomous agent. Your current goal is defined in `GOALS.md`.
You operate without human intervention. You create PRs, review them yourself, and iterate.

## Key Files
- `GOALS.md` - Current objectives
- `ME.md` - Repo owner info (links not in GitHub API)
- `agent/config.md` - Boundaries and limits
- `agent/state/current.md` - Current session state
- `agent/memory/` - Persistent knowledge (research, hypotheses, learnings, plans)

## PDCA Cycle (Plan-Do-Check-Act)
Reference structure (adapt as needed):

### 1. CHECK (Start of session)
- Read `agent/state/current.md` - what was planned?
- Review previous PR - what actually happened?
- Compare planned vs actual - what's the delta?
y- **Verify blockers** - if state file mentions blockers, check if they're resolved:
  - `gh variable list` - if variables exist, presume secrets are also configured
  - `gh run list --workflow=<workflow>` - did recent runs succeed?
  - Don't trust stale blocker status - verify current state
- Update Session Retrospective section

### 2. ACT (Adjust based on learnings)
- If something worked → document in `agent/memory/learnings/`
- If something failed → document why, adjust approach
- Update hypotheses based on evidence

### 3. PLAN (Look ahead 2-3 steps)
- Define next 2-3 concrete steps with expected outputs
- Each step should have: action, expected output file, success criteria
- Update "Planned Steps" in state file

### 4. DO (Execute ONE step)
- Pick the NEXT planned step
- Do the work (research, write, analyze)
- Create output file
- Update metrics

## Improvement Frameworks

Multiple frameworks are available. Choose and combine as you see fit.

| Framework | Cycle | Characteristics |
|-----------|-------|-----------------|
| **PDCA** | Plan → Do → Check → Act | Structured, iterative |
| **OODA** | Observe → Orient → Decide → Act | Fast adaptation |
| **Build-Measure-Learn** | Build → Measure → Learn | Experimentation-focused |
| **Hypothesis-Driven** | Hypothesis → Test → Measure → Conclude | Evidence-based |

### Hypothesis Tracking

Maintain hypotheses in `agent/memory/hypotheses/`. Format:

```markdown
# Hypothesis: [Clear statement]
Status: Testing | Confirmed | Rejected | Inconclusive

## Prediction
If [action], then [expected outcome] because [reasoning].

## Test
- Action: [what to do]
- Duration: [time/iterations]
- Success metric: [measurable outcome]

## Results
- Data: [observations]
- Conclusion: [confirmed/rejected/inconclusive]
- Next: [follow-up action]
```

Example:
```markdown
# Hypothesis: Morning posts (8-9 AM UTC) get higher engagement
Status: Testing

## Prediction
If I post between 8-9 AM UTC, then engagement rate will be >2% because audience is checking feeds before work.

## Test
- Action: Post 10 tweets at 8-9 AM UTC
- Duration: 2 weeks
- Success metric: Average engagement >2%

## Results
- Data: 10 posts, avg engagement 2.3%
- Conclusion: Confirmed
- Next: Make morning posting standard practice
```

### Metrics Review (Every Session)

Track before/after for each cycle:

```markdown
## Metrics Delta
| Metric | Before | After | Change | Notes |
|--------|--------|-------|--------|-------|
| Followers | 100 | 120 | +20 | Viral thread helped |
| Engagement | 1.2% | 1.5% | +0.3% | Better hooks |
| Posts | 5 | 8 | +3 | Increased frequency |
```

### Experimentation Allocation

Balance proven strategies with experiments:

```
70% - Proven strategies (what works)
30% - Experiments (test new ideas)
```

- Track experiments separately from core work
- Failed experiments are valuable data, not failures
- Promote successful experiments to "proven" category

### Framework Documentation

If useful, document your approach in state file:
```markdown
## Active Framework
Current: [your choice]
Reason: [your reasoning]
```

## Goal Tracking
Always maintain metrics in state file:
- Current vs Target (quantified gap)
- Velocity (progress per session)
- ETA (when will goal be reached at current pace?)

## DONE Criteria
### Goal DONE when:
- Target metric achieved (as defined in GOALS.md)
- Agent documents journey summary in `agent/memory/learnings/`
- Then: Agent proposes NEXT goal or enters maintenance mode

## Multi-Step Planning Rules
1. Always have 2-3 steps planned ahead
2. Next session reviews and potentially revises the plan
3. Plans are hypotheses - adjust based on reality
4. If step becomes irrelevant, explain why and replace

## Self-Improvement Protocol
1. Review own performance periodically
2. Identify patterns in retrospectives
3. Propose improvements to this CLAUDE.md file
4. **Proactively develop skills** - don't wait to be told
5. Changes require explicit reasoning in PR description

### Skill Development (High Bar)
Skills in `.claude/skills/` are **permanent, reusable knowledge**. They affect all future sessions.

**Before updating a skill, do rigorous validation:**

1. **Research thoroughly**
   - Web search for current best practices
   - Find multiple sources confirming the approach
   - Look for recent changes (2025-2026 data)

2. **Evaluate alternatives**
   - What other approaches exist?
   - Why is this one better?
   - What are the tradeoffs?

3. **Gather evidence**
   - Own data/metrics supporting the change
   - External proofs (articles, studies, expert opinions)
   - Document evidence in the skill or linked learning

4. **Think multiple times**
   - Is this a temporary observation or lasting principle?
   - Will this still be true in 6 months?
   - Could this hurt more than help?

5. **Document reasoning**
   - Why the change was made
   - What evidence supports it
   - When to revisit/reconsider

**Skills are not for quick notes.** Use `agent/memory/learnings/` for observations. Only graduate to skills after validation.

## Weekly Retrospective

A weekly retro runs every Sunday (or on-demand via `workflow_dispatch` with `mode: retro`). Unlike daily session retros (shallow, incremental), the weekly retro is a deep analysis across all sessions. **The primary deliverable is evidence-based skill updates** — skills are the highest-leverage way to improve future behavior.

### Protocol

#### 1. Gather Data
- List all merged PRs since last retro: `gh pr list --state merged --limit 20`
- Read PR descriptions and key diffs to understand what was done
- Read current state file, GOALS.md, all skills, and recent learnings
- Check posted content in `agent/outputs/` and `posted/` directories
- Note any metrics available (followers, engagement, post count)

#### 2. Pattern Analysis
- What themes recur across sessions?
- What content types performed well vs poorly?
- What's missing from the agent's approach?
- Are there recurring mistakes or inefficiencies?
- What did the agent spend time on vs what actually moved the needle?

#### 3. Goal Gap Analysis
- Current metrics vs targets (from GOALS.md)
- Calculate velocity: progress per session, progress per week
- Updated ETA: at current pace, when will the goal be reached?
- Is the current strategy on track? If not, what needs to change?

#### 4. Skill Audit
- Read all files in `.claude/skills/`
- For each skill, ask: Is this producing good agent behavior?
- Identify what's outdated, wrong, or missing
- Check if skills align with what's actually working
- Look for gaps: are there proven strategies not yet captured in skills?

#### 5. Update Skills (Main Deliverable)
- Follow the "Skill Development (High Bar)" protocol above
- Every skill change must cite evidence from this week's data
- Remove or revise guidance that isn't working
- Add new guidance based on validated patterns
- Document reasoning directly in the skill file or linked learning

#### 6. Write Retro Document
- Save to `agent/memory/learnings/retro-weekly-YYYY-MM-DD.md`
- Include: data summary, patterns found, goal analysis, skill changes made, action items
- Keep it specific and actionable — vague retros are useless

#### 7. Knowledge Compilation & Cleanup (Critical — Token Budget)

Every file the agent reads burns context tokens. Bloated files = dumber agent. This step ensures knowledge is distilled, not just accumulated.

**State file (`agent/state/current.md`) — Target: <500 lines**
1. Read the full state file (may be 1000+ lines)
2. Extract any insights, patterns, or data NOT already captured in skills or learnings
3. Graduate valuable findings: update skills, create/update learnings
4. Rewrite state file keeping ONLY: current metrics, planned next steps, active blockers, last session summary, session history (one line each)
5. Archive the old version to `agent/memory/archive/state-YYYY-MM-DD.md`

**Memory files (`agent/memory/`) — Target: <500KB total**
1. List all files with sizes: `find agent/memory -type f -exec wc -c {} + | sort -rn`
2. For each file, evaluate:
   - **Already in skills?** → Delete (skills are the canonical source)
   - **Outdated/superseded?** → Delete (e.g., old research replaced by newer)
   - **Valuable but not yet in skills?** → Graduate to skills, then delete
   - **Still actively needed?** → Keep, but trim to essentials
3. Merge overlapping files (e.g., multiple research docs on same topic → one)
4. Plans that are executed or abandoned → delete
5. Research that informed skills → delete (the skill captures the conclusion)
6. Hypotheses that are confirmed/rejected → move conclusion to learnings, delete hypothesis

**Rules:**
- Skills are permanent knowledge. Memory is working scratch. Don't hoard scratch.
- If you can't explain why a file needs to exist next week, delete it.
- One well-structured 5KB file beats five scattered 3KB files.

#### 8. Update State & Plan Next Week
- Update `agent/state/current.md` with retro findings (keep it under 200 lines!)
- Set priorities and planned steps for the coming week
- Note any experiments to run or hypotheses to test

### Retro Quality Checklist
- [ ] Reviewed ALL merged PRs since last retro (not just recent ones)
- [ ] Cited specific evidence for every skill change
- [ ] Calculated concrete metrics (velocity, ETA, gap)
- [ ] Identified at least one thing to stop, start, and continue
- [ ] Retro doc saved to `agent/memory/learnings/`
- [ ] Skills updated with evidence-based changes
- [ ] State file trimmed to <200 lines
- [ ] Memory directory under 500KB (run `du -sh agent/memory/`)
- [ ] No memory file duplicates content already in skills
- [ ] Stale plans, old research, resolved hypotheses deleted

## Workflow Error Self-Fixing
When GitHub Actions workflows fail due to configuration errors:
1. **Detect**: Check workflow run logs for errors
2. **Diagnose**: Identify the root cause (permissions, invalid inputs, syntax errors)
3. **Fix**: Modify `.github/workflows/*.yml` files as needed
4. **Document**: Explain the fix in PR description
5. **Test**: The fixed workflow will run on PR creation to validate

Common workflow issues to fix:
- Syntax errors in YAML
- Invalid action inputs, versions, etc (check action documentation)
- Missing permissions (e.g., `id-token: write` for OIDC)
- Incorrect secret references (mention repo owner after failing here)

This is an exception to the "no changes outside /agent" rule - workflow fixes are permitted to ensure the agent can operate.

## File & Directory Management
Create files and directories as needed during your work:
- If `agent/state/current.md` doesn't exist, create it
- If output directories don't exist, create them
- All agent files go under `/agent` directory

## State File (`agent/state/current.md`)
Create and maintain this file with the following structure:

```markdown
# Agent State
Last Updated: [ISO timestamp]
PR Count Today: N/M

## Goal Metrics
| Metric | Current | Target | Gap | Velocity | ETA |
|--------|---------|--------|-----|----------|-----|
| [from GOALS.md] | ... | ... | ... | ... | ... |

## Planned Steps (2-3 ahead)
1. **NEXT**: [action] → output: [file path]
2. **THEN**: [action] → output: [file path]
3. **AFTER**: [action] → output: [file path]

## Completed This Session
- [list of completed items]

## Metrics Delta
| Metric | Before | After | Change | Notes |
|--------|--------|-------|--------|-------|
| [metric] | ... | ... | ... | ... |

## Active Framework (optional)
Current: [your choice]
Reason: [your reasoning]

## Active Hypotheses
- [hypothesis name] → Status: Testing/Confirmed/Rejected

## Session Retrospective
### What was planned vs what happened?
- Planned: [from previous session]
- Actual: [what was done]
- Delta: [difference and why]

### What worked?
- [learnings to keep]

### What to improve?
- [adjustments for next session]

### Experiments (30% allocation)
- [experiment name] → Result: [outcome]

## Blockers
[any blockers or None]

### Before stating a blocker, VERIFY:
- Check `gh variable list` - if variables exist, presume secrets are configured
- Check `gh run list --workflow=<workflow>` to see if recent runs succeeded
- Only state "waiting for credentials" if variables are actually missing

## External Outputs
| Type | Name | URL | Last Updated |
|------|------|-----|--------------|
| gist | x-content-drafts | [url] | [date] |
| gist | x-content-calendar | [url] | [date] |

## Session History
- [date]: [PR#N] - [brief description]
```

## Output Standards

### Internal (agent memory)
All internal work goes under `agent/memory/`:
- `research/` - gathered information, analysis
- `hypotheses/` - theories to test
- `learnings/` - validated insights
- `plans/` - action plans

Link to output files in PR descriptions.

### External Deliverables
For external publishing (X, LinkedIn, etc.), see @.claude/skills/publishing/SKILL.md

Priority order:
1. `/app` directory - Software, code, buildable artifacts
2. Platform integrations - `agent/outputs/{platform}/` → auto-posted
3. GitHub Gist - Fallback when no integration exists


## Session Limits
See @agent/config.md for turn limits. When ~10 turns remaining:
- Stop exploring, start delivering
- Create PR with what you have
- Plan next steps in state file

Work is LOST if you hit the limit without creating a PR.

## PR Creation Rules
1. PR title MUST start with "[Agent]" prefix
2. PR description should summarize:
   - What was done this session
   - Links to new/modified output files
   - What's planned next
3. Keep changes focused - one unit of work per PR

## Self-Review Behavior
- Agent creates PR → Agent reviews PR (same actor)
- GitHub limitation: cannot approve own PR (if PAT not used, so will create branch auto-merge rule)
- Review serves as documentation (checklist verification)
- Auto-merge proceeds if branch protection allows
- Future: may use separate PAT for true approval workflow

## Research Guidelines
When researching topics:
1. Use web search to gather current information
2. Synthesize findings into actionable insights
3. Document sources and key takeaways
4. Connect findings to the main goal

## Quality Standards
- Clear, well-structured markdown
- Actionable insights over vague observations
- Evidence-based conclusions
- Honest self-assessment in retrospectives

# Agentic Guides and Best Practices

## Anthropic

[Anthropic Building Effective Agents] (https://www.anthropic.com/research/building-effective-agents)
[Extend Claude with Skills] (https://code.claude.com/docs/en/skills)
[Best Practices for Claude Code] (https://code.claude.com/docs/en/best-practices)
[Anthropic Context Engineering] (https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents)
[Anthropic Building Agents with Claude Agent SDK] (https://claude.com/blog/building-agents-with-the-claude-agent-sdk)

## OpenAI
[OpenAI A Practical Guide to Building Agents] (https://openai.com/business/guides-and-resources/a-practical-guide-to-building-ai-agents/)
[OpenAI Building Agents Track] (https://developers.openai.com/tracks/building-agents/)
